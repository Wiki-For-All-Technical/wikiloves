"""
Process all campaign country data files from quarry_data/ folder
and update the catalog.py with comprehensive country-level statistics.

Usage:
    python backend/scripts/process_all_country_data.py

This script will:
1. Read all *_country_data.json files from quarry_data/
2. Process them into the correct format
3. Update catalog.py with the data
"""

import json
import os
import sys
from collections import defaultdict
from typing import Dict, List, Any

# Add parent directory to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

# Mapping of JSON files to campaign slugs
FILE_CAMPAIGN_MAPPING = {
    'africa_country_data.json': 'africa',
    'africa_country_converted.json': 'africa',
    'folklore_country_data.json': 'folklore',
    'folklore_country_converted.json': 'folklore',
    'science_country_data.json': 'science',
    'science_country_converted.json': 'science',
    'food_country_data.json': 'food',
    'food_country_converted.json': 'food',
    'public_art_country_data.json': 'public-art',
    'public_art_country_converted.json': 'public-art',
    # Also handle the multiyear files if they have country data
    'earth_country_converted.json': 'earth',
    'monuments_county_converted.json': 'monuments',
}


def load_quarry_json(file_path: str) -> List[Dict]:
    """Load and parse a Quarry JSON export file."""
    with open(file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # Handle Quarry export format with headers and rows
    if isinstance(data, dict) and 'headers' in data and 'rows' in data:
        headers = data['headers']
        rows = data['rows']
        result = []
        for row in rows:
            entry = {}
            for i, header in enumerate(headers):
                if i < len(row):
                    entry[header] = row[i]
            result.append(entry)
        return result
    
    # Handle already converted format (list of dicts)
    elif isinstance(data, list):
        return data
    
    return []


def process_country_data(data: List[Dict]) -> Dict[int, Dict]:
    """
    Process country data and organize by year with proper country breakdown.
    """
    years_data = defaultdict(lambda: {
        'uploads': 0,
        'uploaders': 0,
        'images_used': 0,
        'new_uploaders': 0,
        'countries': 0,
        'country_stats': []
    })
    
    for entry in data:
        year = entry.get('year')
        if not year:
            continue
            
        country = entry.get('country', 'Global')
        uploads = entry.get('uploads', 0)
        uploaders = entry.get('uploaders', 0)
        images_used = entry.get('images_used', uploads)
        new_uploaders = entry.get('new_uploaders', 0)
        
        if country == 'Global' or country is None:
            # Global/total row
            years_data[year]['uploads'] = max(years_data[year]['uploads'], uploads)
            years_data[year]['uploaders'] = max(years_data[year]['uploaders'], uploaders)
            years_data[year]['images_used'] = max(years_data[year]['images_used'], images_used)
            years_data[year]['new_uploaders'] = max(years_data[year]['new_uploaders'], new_uploaders)
        else:
            # Country-specific row
            years_data[year]['country_stats'].append({
                'name': country,
                'uploads': uploads,
                'uploaders': uploaders,
                'images_used': images_used,
                'new_uploaders': new_uploaders,
                'rank': 0
            })
    
    # Post-process: sort, rank, and calculate totals
    for year, year_data in years_data.items():
        # Sort by uploads descending
        year_data['country_stats'].sort(key=lambda x: x['uploads'], reverse=True)
        
        # Assign ranks
        for i, stat in enumerate(year_data['country_stats'], 1):
            stat['rank'] = i
        
        # Count countries
        year_data['countries'] = len(year_data['country_stats'])
        
        # If no global total, sum from countries
        if year_data['uploads'] == 0 and year_data['country_stats']:
            year_data['uploads'] = sum(c['uploads'] for c in year_data['country_stats'])
            year_data['uploaders'] = sum(c['uploaders'] for c in year_data['country_stats'])
            year_data['images_used'] = sum(c['images_used'] for c in year_data['country_stats'])
            year_data['new_uploaders'] = sum(c['new_uploaders'] for c in year_data['country_stats'])
    
    return dict(years_data)


def write_catalog(output_path: str, competitions: List[Dict]):
    """Write the catalog.py file."""
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write('"""\n')
        f.write('Campaign catalog data - Auto-generated with country data\n')
        f.write('Generated by process_all_country_data.py\n')
        f.write('"""\n\n')
        f.write('COMPETITIONS = [\n')
        
        for comp in competitions:
            f.write('    {\n')
            f.write(f'        "slug": "{comp["slug"]}",\n')
            f.write(f'        "name": "{comp["name"]}",\n')
            f.write(f'        "short_label": "{comp.get("short_label", comp["name"])}",\n')
            f.write(f'        "tagline": "{comp.get("tagline", "")}",\n')
            f.write(f'        "accent_color": "{comp.get("accent_color", "#1f8a70")}",\n')
            f.write(f'        "hero_image": "{comp.get("hero_image", "")}",\n')
            f.write(f'        "logo": "{comp.get("logo", "")}",\n')
            f.write(f'        "path_segment": "{comp.get("path_segment", comp["slug"])}",\n')
            f.write('        "years": [\n')
            
            for year_data in comp.get('years', []):
                f.write('            {\n')
                f.write(f'                "year": {year_data["year"]},\n')
                f.write(f'                "uploads": {year_data.get("uploads", 0)},\n')
                f.write(f'                "uploaders": {year_data.get("uploaders", 0)},\n')
                f.write(f'                "images_used": {year_data.get("images_used", 0)},\n')
                f.write(f'                "new_uploaders": {year_data.get("new_uploaders", 0)},\n')
                f.write(f'                "countries": {year_data.get("countries", 0)},\n')
                f.write('                "country_stats": [\n')
                
                for country_stat in year_data.get('country_stats', []):
                    f.write('                    {\n')
                    f.write(f'                        "name": {json.dumps(country_stat["name"])},\n')
                    f.write(f'                        "uploads": {country_stat.get("uploads", 0)},\n')
                    f.write(f'                        "uploaders": {country_stat.get("uploaders", 0)},\n')
                    f.write(f'                        "images_used": {country_stat.get("images_used", 0)},\n')
                    f.write(f'                        "new_uploaders": {country_stat.get("new_uploaders", 0)},\n')
                    f.write(f'                        "rank": {country_stat.get("rank", 0)}\n')
                    f.write('                    },\n')
                
                f.write('                ]\n')
                f.write('            },\n')
            
            f.write('        ]\n')
            f.write('    },\n')
        
        f.write(']\n\n')
        f.write('COUNTRIES = []  # Country data can be generated separately\n')


def main():
    """Main function to process all country data files."""
    print("=" * 60)
    print("Processing All Campaign Country Data")
    print("=" * 60)
    
    # Paths
    quarry_dir = os.path.join(os.path.dirname(__file__), '..', '..', 'quarry_data')
    catalog_path = os.path.join(os.path.dirname(__file__), '..', 'data', 'catalog.py')
    
    # Load current catalog
    exec_globals = {}
    with open(catalog_path, 'r', encoding='utf-8') as f:
        exec(f.read(), exec_globals)
    
    competitions = exec_globals.get('COMPETITIONS', [])
    
    # Track what we've updated
    updated_campaigns = []
    
    # Process each file in quarry_data
    if os.path.exists(quarry_dir):
        for filename in os.listdir(quarry_dir):
            if filename in FILE_CAMPAIGN_MAPPING:
                campaign_slug = FILE_CAMPAIGN_MAPPING[filename]
                file_path = os.path.join(quarry_dir, filename)
                
                print(f"\nProcessing {filename} for {campaign_slug}...")
                
                try:
                    data = load_quarry_json(file_path)
                    if data:
                        years_data = process_country_data(data)
                        
                        # Find and update the campaign
                        for comp in competitions:
                            if comp['slug'] == campaign_slug:
                                # Build new years list
                                new_years = []
                                for year in sorted(years_data.keys(), reverse=True):
                                    yd = years_data[year]
                                    new_years.append({
                                        'year': year,
                                        'uploads': yd['uploads'],
                                        'uploaders': yd['uploaders'],
                                        'images_used': yd['images_used'],
                                        'new_uploaders': yd['new_uploaders'],
                                        'countries': yd['countries'],
                                        'country_stats': yd['country_stats']
                                    })
                                
                                comp['years'] = new_years
                                
                                total_countries = sum(len(y['country_stats']) for y in new_years)
                                print(f"  Updated {campaign_slug}: {len(new_years)} years, {total_countries} country entries")
                                updated_campaigns.append(campaign_slug)
                                break
                except Exception as e:
                    print(f"  Error processing {filename}: {e}")
    
    # Write updated catalog
    write_catalog(catalog_path, competitions)
    
    print("\n" + "=" * 60)
    print(f"Updated {len(updated_campaigns)} campaigns:")
    for camp in updated_campaigns:
        print(f"  - {camp}")
    print(f"\nCatalog saved to: {catalog_path}")
    print("=" * 60)


if __name__ == '__main__':
    main()

